{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vivek/Downloads/kaggle_ndsb2-master/data_segmenter_trainset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/vivek/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('/home/vivek/Downloads/kaggle_ndsb2-master/data_segmenter_trainset')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "path = os.listdir()\n",
    "#gives us the matching annotated images with their masks in a dataframe.  just the strings\n",
    "pairing_table = pd.read_csv('train1.lst',delimiter='\\t',names=['image','mask'])\n",
    "pairing_table.head()\n",
    "print(type(pairing_table['image'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9068, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairing_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the images one by one\n",
    "from PIL import Image\n",
    "\n",
    "def viz_help(path):\n",
    "    img = Image.open(path)\n",
    "    img.show()\n",
    "    \n",
    "def vizs(image_name):\n",
    "    viz_help('/home/vivek/Downloads/kaggle_ndsb2-master/data_segmenter_trainset/'+image_name)\n",
    "\n",
    "vizs('0001_00000sax_12_09899_IM-4567-0012.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_table = pairing_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 184, 1)\n",
      "(9068,)\n",
      "(184, 184, 1)\n",
      "(9068,)\n"
     ]
    }
   ],
   "source": [
    "path = '/home/vivek/Downloads/kaggle_ndsb2-master/data_segmenter_trainset/'\n",
    "\n",
    "\n",
    "for ii in range(0,2000):\n",
    "    new_path = os.path.join(path,image_table['image'][ii])\n",
    "    img = Image.open(new_path)\n",
    "    img2 = np.array(img.getdata()).reshape(184, 184, -1)\n",
    "    image_table['image'][ii] = img2\n",
    "    img.close()\n",
    "    \n",
    "    \n",
    "for ii in range(0,2000):\n",
    "    new_path = os.path.join(path,image_table['mask'][ii])\n",
    "    img = Image.open(new_path)\n",
    "    img2 = np.array(img.getdata()).reshape(184, 184, -1)\n",
    "    image_table['mask'][ii] = img2\n",
    "    img.close()\n",
    "    \n",
    "\n",
    "\n",
    "print(image_table['image'][0].shape)\n",
    "print(image_table['image'].shape)\n",
    "print(image_table['mask'][0].shape)\n",
    "print(image_table['mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (2000, 184, 184, 1)\n",
      "<class 'numpy.ndarray'> (2000, 184, 184, 1)\n"
     ]
    }
   ],
   "source": [
    "#convert our data into the proper format to feed into the neural network\n",
    "\n",
    "x = np.stack(image_table['image'][:2000].values)\n",
    "print(type(x),x.shape)\n",
    "\n",
    "y = np.stack(image_table['mask'][:2000].values)\n",
    "print(type(y),y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#load in validation table\n",
    "\n",
    "validate_pairing_table = pd.read_csv('validate1.lst',delimiter='\\t',names=['image','mask'])\n",
    "\n",
    "val_image_table = validate_pairing_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(0,100):\n",
    "    new_path = os.path.join(path,val_image_table['image'][ii])\n",
    "    img = Image.open(new_path)\n",
    "    img2 = np.array(img.getdata()).reshape(184, 184, -1)\n",
    "    val_image_table['image'][ii] = img2\n",
    "    img.close()\n",
    "    \n",
    "    \n",
    "for ii in range(0,100):\n",
    "    new_path = os.path.join(path,val_image_table['mask'][ii])\n",
    "    img = Image.open(new_path)\n",
    "    img2 = np.array(img.getdata()).reshape(184, 184, -1)\n",
    "    val_image_table['mask'][ii] = img2\n",
    "    img.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/vivek/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 184, 184, 1) (500, 184, 184, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split( x,y, random_state = 2018, test_size = 0.25)\n",
    "x_train = np.asarray(x_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "print(x_train.shape, x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#convert into tensor of proper shape\n",
    "print(type(image_table['image'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/vivek/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/vivek/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 184, 184, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 184, 184, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 184, 184, 64) 36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 92, 92, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 92, 92, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 92, 92, 128)  147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 46, 46, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 46, 46, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 46, 46, 256)  590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 23, 23, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 23, 23, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 23, 23, 512)  2359808     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 46, 46, 256)  524544      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 46, 46, 256)  0           conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 46, 46, 512)  0           dropout_4[0][0]                  \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 46, 46, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 46, 46, 256)  590080      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 92, 92, 128)  131200      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 92, 92, 128)  0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 92, 92, 256)  0           dropout_5[0][0]                  \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 92, 92, 128)  295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 92, 92, 128)  147584      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 184, 184, 64) 32832       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 184, 184, 64) 0           conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 184, 184, 2)  1154        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 184, 184, 1)  3           conv2d_13[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,586,565\n",
      "Trainable params: 7,586,565\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#import keras dependencies\n",
    "import keras\n",
    "from keras import Sequential,Model\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from keras.layers import Conv2D, MaxPool2D, Activation, UpSampling2D,Conv2DTranspose, concatenate\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import backend as keras\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "inputs = Input(shape = (184,184,1))\n",
    "\n",
    "#First Block\n",
    "b1_conv1 = Conv2D(64,(3,3),activation='relu',padding='same',kernel_initializer = 'glorot_normal')(inputs)\n",
    "b1_conv2 = Conv2D(64,(3,3),activation='relu',padding='same',kernel_initializer = 'glorot_normal')(b1_conv1)\n",
    "b1_pool = MaxPool2D((2,2))(b1_conv2)  \n",
    "drop1= Dropout(0.2)(b1_pool)\n",
    "\n",
    "#Second Block\n",
    "b2_conv1 = Conv2D(128,(3,3),activation='relu',padding='same',kernel_initializer = 'glorot_normal')(b1_pool)\n",
    "b2_conv2 = Conv2D(128,(3,3),activation='relu',padding='same')(b2_conv1)\n",
    "b2_pool = MaxPool2D((2,2))(b2_conv2)\n",
    "drop2= Dropout(0.2)(b2_pool)\n",
    "\n",
    "#Third Block\n",
    "b3_conv1 = Conv2D(256,(3,3),activation='relu',padding='same')(b2_pool)\n",
    "b3_conv2 = Conv2D(256,(3,3),activation='relu',padding='same')(b3_conv1)\n",
    "b3_pool = MaxPool2D((2,2))(b3_conv2)\n",
    "drop3= Dropout(0.2)(b3_pool)\n",
    "\n",
    "#Fourth Block\n",
    "b4_conv1 = Conv2D(512,(3,3),activation='relu',padding='same')(b3_pool)\n",
    "b4_conv2 = Conv2D(512,(3,3),activation='relu',padding='same')(b4_conv1)\n",
    "b4_up = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(b4_conv2)\n",
    "drop4= Dropout(0.2)(b4_up)\n",
    "\n",
    "\n",
    "#Fifth Block\n",
    "b5_concat = concatenate([drop4, b3_conv2], axis=3)\n",
    "b5_conv1 = Conv2D(256,(3,3),activation='relu',padding='same')(b5_concat)\n",
    "b5_conv2 = Conv2D(256,(3,3),activation='relu',padding='same')(b5_conv1)\n",
    "b5_up = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(b5_conv2)\n",
    "drop5= Dropout(0.2)(b5_up)\n",
    "\n",
    "#Sixth Block\n",
    "b6_concat = concatenate([drop5, b2_conv2], axis=3)\n",
    "b6_conv1 = Conv2D(128,(3,3),activation='relu',padding='same')(b6_concat)\n",
    "b6_conv2 = Conv2D(128,(3,3),activation='relu',padding='same')(b6_conv1)\n",
    "b6_up = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(b6_conv2)\n",
    "drop6= Dropout(0.2)(b6_up)\n",
    "\n",
    "\n",
    "#Output\n",
    "output_layer1 = Conv2D(2,(3,3),activation='relu',padding='same')(drop6)\n",
    "output_layer = Conv2D(1,(1,1),activation='sigmoid',padding='same')(output_layer1)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "model = Model(inputs =inputs,outputs=output_layer)\n",
    "model.summary()\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "smooth = 1.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "\n",
    "model.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef], loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 184, 184, 1) (2000, 184, 184, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(history, save_path = None, dpi=600):\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['dice_coef'])\n",
    "    plt.plot(history.history['val_dice_coef'])\n",
    "    plt.title('dice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 29s 24ms/step - loss: -1.4595 - dice_coef: 1.4595 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 26s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 25s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 25s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 25s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 26s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 25s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 25s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 25s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 26s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 26s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 26s 22ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 25s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 26s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 26s 22ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 16/20\n",
      "1200/1200 [==============================] - 26s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 17/20\n",
      "1200/1200 [==============================] - 25s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 18/20\n",
      "1200/1200 [==============================] - 25s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 19/20\n",
      "1200/1200 [==============================] - 26s 21ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n",
      "Epoch 20/20\n",
      "1200/1200 [==============================] - 26s 22ms/step - loss: -1.4599 - dice_coef: 1.4599 - val_loss: -1.4376 - val_dice_coef: 1.4376\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, batch_size=1, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
